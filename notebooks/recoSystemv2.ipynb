{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7446bb1a179f4f5d9df30dfb6fded8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87868594ad6744e9b47a5ed3d61b90d2",
              "IPY_MODEL_bf67f3ed11004016b964f905a8a1c2d5",
              "IPY_MODEL_f340566de38240c6942444acff370618"
            ],
            "layout": "IPY_MODEL_dc2e181e29ab4d9ab9fe6f3b584ec253"
          }
        },
        "87868594ad6744e9b47a5ed3d61b90d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b460f0748d44fdca62ba2ae47f2fa82",
            "placeholder": "​",
            "style": "IPY_MODEL_7989283e1a5d43b69c90c5a6d415e92e",
            "value": "100%"
          }
        },
        "bf67f3ed11004016b964f905a8a1c2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2178f3970af549d9a9a1e02ef03d08f5",
            "max": 210,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8638cb9aa3f4bcbaaaa2be6b2e7154c",
            "value": 210
          }
        },
        "f340566de38240c6942444acff370618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d6ac982565245eeaa96c9dae26ab167",
            "placeholder": "​",
            "style": "IPY_MODEL_9e38b14962524ea791fd4924db1a9441",
            "value": " 210/210 [00:26&lt;00:00, 14.73it/s]"
          }
        },
        "dc2e181e29ab4d9ab9fe6f3b584ec253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b460f0748d44fdca62ba2ae47f2fa82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7989283e1a5d43b69c90c5a6d415e92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2178f3970af549d9a9a1e02ef03d08f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8638cb9aa3f4bcbaaaa2be6b2e7154c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d6ac982565245eeaa96c9dae26ab167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e38b14962524ea791fd4924db1a9441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33070908f55b4ec6bc00640de3ca18a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8baae26f7edc425f8496fe7c131dac72",
              "IPY_MODEL_c98021097f63482d90b2083c1565965b",
              "IPY_MODEL_1c60a23344ee456dab1fd38f3f0192cc"
            ],
            "layout": "IPY_MODEL_fba18c7f676f43a79bbccf1a45618183"
          }
        },
        "8baae26f7edc425f8496fe7c131dac72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec627cfccd26472fb405c2539d63c994",
            "placeholder": "​",
            "style": "IPY_MODEL_f184fd9d12f1484aa7f2a9c6d033090a",
            "value": "100%"
          }
        },
        "c98021097f63482d90b2083c1565965b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad91ef734934498ba91b026d49204c5b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39b4e78d1c5c48c7b9215946e309ddc0",
            "value": 1
          }
        },
        "1c60a23344ee456dab1fd38f3f0192cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b2754aaad97497ebd52fbaf8ab94ce0",
            "placeholder": "​",
            "style": "IPY_MODEL_e9e638ca79c44ddfbff39c8b8f8b708d",
            "value": " 1/1 [00:01&lt;00:00,  1.02s/it]"
          }
        },
        "fba18c7f676f43a79bbccf1a45618183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec627cfccd26472fb405c2539d63c994": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f184fd9d12f1484aa7f2a9c6d033090a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad91ef734934498ba91b026d49204c5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39b4e78d1c5c48c7b9215946e309ddc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b2754aaad97497ebd52fbaf8ab94ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9e638ca79c44ddfbff39c8b8f8b708d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c6d3120b0be41ada351d0093d8d6676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c8390aa92d8418f9baeaaa9b23fa05a",
              "IPY_MODEL_3f8cc01b79b34596ab064245c24b670b",
              "IPY_MODEL_76d83b593d244c69902747d234e5dd53"
            ],
            "layout": "IPY_MODEL_7ac40f4670d644978e2f3045cdba6429"
          }
        },
        "2c8390aa92d8418f9baeaaa9b23fa05a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9caf9b12d3ca474ab3fae74451ad10e5",
            "placeholder": "​",
            "style": "IPY_MODEL_4dd6c77712564b7b9c73fcbfed4225fa",
            "value": "100%"
          }
        },
        "3f8cc01b79b34596ab064245c24b670b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_036e7e8d99224a1f995de418bd5c7b22",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ced8fb2763a4545ace2d6f2e95ca288",
            "value": 3
          }
        },
        "76d83b593d244c69902747d234e5dd53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c631dae62d934649bb90459a4e5a9028",
            "placeholder": "​",
            "style": "IPY_MODEL_78ef43c91f074beaab47098f4a69e3a5",
            "value": " 3/3 [00:00&lt;00:00,  3.85it/s]"
          }
        },
        "7ac40f4670d644978e2f3045cdba6429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9caf9b12d3ca474ab3fae74451ad10e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dd6c77712564b7b9c73fcbfed4225fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "036e7e8d99224a1f995de418bd5c7b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ced8fb2763a4545ace2d6f2e95ca288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c631dae62d934649bb90459a4e5a9028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78ef43c91f074beaab47098f4a69e3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_3o6ozV_JHvPeAYZdSSRn1FtXu8njTnewDh1TXcNgecMfZVS6dUynnabzCHMXf59FijkWhu\"\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "pG_wbrcMXTGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community langchain-core pinecone\n",
        "!pip install -U langchain-huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JulKWV_5d4gX",
        "outputId": "ef870961-ba26-4346-eefb-1bbdc4514a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.12/dist-packages (7.3.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.35)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2025.10.5)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from pinecone) (1.8.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (2.1.2)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (1.0.0)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain) (1.11.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.35.3)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.22.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.1.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (0.4.35)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (2.11.10)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (8.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.10.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.llms import HuggingFaceEndpoint"
      ],
      "metadata": {
        "id": "Rn73gc6BdxKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- GenAI (LangChain) ---\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "# from langchain.chains import LLMChain\n"
      ],
      "metadata": {
        "id": "hXpczzLHdIj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 0. Imports and Setup ---\n",
        "\n",
        "# Install necessary libraries\n",
        "\n",
        "\n",
        "# --- Core Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import torch\n",
        "from tqdm.auto import tqdm # For progress bars\n",
        "\n",
        "# --- ML / NLP / CV (HuggingFace Transformers) ---\n",
        "from transformers import AutoProcessor, AutoModel, pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# --- Vector Database (Pinecone) ---\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# --- GenAI (LangChain) ---\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "# from langchain.chains import LLMChain   # ✅ new location\n",
        "\n",
        "\n",
        "# --- Evaluation ---\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# --- Environment Setup ---\n",
        "# Reasoning: We use environment variables to store sensitive API keys.\n",
        "# This is much safer than hardcoding them.\n",
        "# You MUST set these in your environment (e.E., in a .env file or your OS)\n",
        "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
        "HUGGINGFACEHUB_API_TOKEN = os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "\n",
        "if not PINECONE_API_KEY or not HUGGINGFACEHUB_API_TOKEN:\n",
        "    print(\"=\"*50)\n",
        "    print(\"WARNING: API keys not found in environment variables.\")\n",
        "    print(\"Please set PINECONE_API_KEY and HUGGINGFACEHUB_API_TOKEN.\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "# --- Device Setup (for PyTorch) ---\n",
        "# Reasoning: We check if a GPU (like CUDA or Apple's MPS) is available.\n",
        "# This will make our embedding generation *significantly* faster.\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    DEVICE = torch.device(\"mps\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upFWz6VgVFdI",
        "outputId": "2c80c9bb-362b-4d3b-890b-3a8367209d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load and Preprocess Data ---\n",
        "\n",
        "# Reasoning: We need a clean, consistent dataset. These steps ensure\n",
        "# data types are correct and missing values are handled before\n",
        "# feeding data into our models.\n",
        "\n",
        "DATA_FILE_PATH = 'data/intern_data_ikarus.csv' # Adjust if your path is different\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(DATA_FILE_PATH)\n",
        "    print(f\"Successfully loaded data. Shape: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Dataset file not found at {DATA_FILE_PATH}.\")\n",
        "    print(\"Please ensure the file is in the 'data' directory.\")\n",
        "    # Create a mock DataFrame to allow the rest of the notebook to run\n",
        "    df = pd.DataFrame({\n",
        "        'uniq_id': [str(i) for i in range(10)],\n",
        "        'title': ['Comfy Chair', 'Large Sofa', 'Modern Table', 'Bright Lamp', 'Wooden Chair', 'Patio Set', 'Bookshelf', 'Office Desk', 'King Bed', 'Nightstand'],\n",
        "        'description': ['A very comfortable chair for your living room.', 'A large sofa, perfect for the whole family.', 'A sleek modern table.', 'A bright lamp to light up your desk.', 'A sturdy wooden chair.', 'Outdoor patio set with 4 chairs.', 'Tall bookshelf for all your books.', 'A professional office desk.', 'A large king-sized bed frame.', 'A small nightstand.'],\n",
        "        'price': [199.99, 799.00, 350.50, 80.00, 150.00, 450.00, 250.00, 300.00, 899.00, 120.00],\n",
        "        'categories': [\"['Home', 'Furniture', 'Chair']\", \"['Home', 'Furniture', 'Sofa']\", \"['Home', 'Furniture', 'Table']\", \"['Home', 'Decor', 'Lamp']\", \"['Home', 'Furniture', 'Chair']\", \"['Outdoor', 'Furniture', 'Patio Set']\", \"['Home', 'Furniture', 'Bookshelf']\", \"['Home', 'Furniture', 'Desk']\", \"['Home', 'Furniture', 'Bed']\", \"['Home', 'Furniture', 'Nightstand']\"],\n",
        "        'brand': ['BrandA', 'BrandB', 'BrandA', 'BrandC', 'BrandA', 'BrandD', 'BrandB', 'BrandA', 'BrandE', 'BrandE'],\n",
        "        'material': ['Wood', 'Fabric', 'Glass', 'Metal', 'Wood', 'Metal', 'Wood', 'Wood', 'Fabric', 'Wood'],\n",
        "        'color': ['Brown', 'Gray', 'Black', 'Silver', 'Brown', 'Black', 'White', 'Brown', 'Gray', 'White'],\n",
        "        'images': [\"['https_www.example.com/img1.jpg']\"] * 10 # Mock images\n",
        "    })\n",
        "    print(\"Loaded mock data to proceed.\")\n",
        "\n",
        "\n",
        "# --- Data Cleaning Steps ---\n",
        "# 1. Drop duplicates\n",
        "df.drop_duplicates(subset='uniq_id', inplace=True)\n",
        "\n",
        "# 2. Handle missing 'description'\n",
        "df['description'] = df['description'].fillna('')\n",
        "\n",
        "# 3. Drop rows with missing critical info\n",
        "df.dropna(subset=['price', 'title', 'categories', 'images', 'uniq_id'], inplace=True)\n",
        "\n",
        "# 4. Parse 'categories'\n",
        "def parse_string_list(x):\n",
        "    try:\n",
        "        return re.findall(r\"'(.*?)'\", str(x))\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "df['categories_list'] = df['categories'].apply(parse_string_list)\n",
        "df['primary_category'] = df['categories_list'].apply(lambda x: x[-1] if len(x) > 0 else 'Unknown')\n",
        "\n",
        "# 5. Parse 'images'\n",
        "# Reasoning: We need a single, valid image URL to feed to our CV model.\n",
        "# We'll take the *first* image from the list.\n",
        "df['image_url_list'] = df['images'].apply(parse_string_list)\n",
        "df['first_image_url'] = df['image_url_list'].apply(lambda x: x[0] if len(x) > 0 else None)\n",
        "df.dropna(subset=['first_image_url'], inplace=True) # Drop items with no images\n",
        "\n",
        "# 6. Create a combined text field for embedding\n",
        "# Reasoning: Combining title and description gives our NLP model\n",
        "# more context, resulting in a better semantic vector.\n",
        "df['text_to_embed'] = df['title'] + \" | \" + df['description']\n",
        "\n",
        "# --- Sample the data for this assignment ---\n",
        "# Reasoning: Embedding 10,000+ items can take a long time. For a 2-day\n",
        "# project, it's wise to start with a smaller sample (e.g., 1000 items)\n",
        "# to prove the pipeline works end-to-end.\n",
        "# For the final submission, you can run it on the full dataset.\n",
        "df_sample = df.sample(n=min(1000, df.shape[0]), random_state=42)\n",
        "\n",
        "print(f\"Data cleaned. Using a sample of {df_sample.shape[0]} items for modeling.\")\n",
        "print(df_sample[['uniq_id', 'text_to_embed', 'first_image_url', 'primary_category']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3Lj7agKX-qq",
        "outputId": "ff4e6179-c432-46b7-d481-764bd49d518f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded data. Shape: (312, 12)\n",
            "Data cleaned. Using a sample of 210 items for modeling.\n",
            "                                  uniq_id  \\\n",
            "53   9762324d-bb95-5daa-a613-7c5f77eb01f6   \n",
            "262  6aaac02f-cfdb-5330-88e5-fd88a1857f51   \n",
            "139  e558c4f4-12f2-5cfd-a314-d69c22675547   \n",
            "298  c88138fb-5c2c-5f19-939a-a18c479ce897   \n",
            "107  54e4f202-a43e-5859-b47e-3c81ef395b31   \n",
            "\n",
            "                                         text_to_embed  \\\n",
            "53   Franklin Sports NFL Storage Ottoman + Containe...   \n",
            "262  SLLFLY Water Bottle Organizer,Stackable Water ...   \n",
            "139  Homevany Bamboo Wine Rack,4 Tier, Wine Bottle ...   \n",
            "298  KINGYES Folding Adjustable Backrest Adirondack...   \n",
            "107  Xchouxer Side Tables Natural Bamboo Sofa Armre...   \n",
            "\n",
            "                                       first_image_url  \\\n",
            "53   https://m.media-amazon.com/images/I/31ptZB+wS-...   \n",
            "262  https://m.media-amazon.com/images/I/51EAJVwOuL...   \n",
            "139  https://m.media-amazon.com/images/I/51DO5hfgdK...   \n",
            "298  https://m.media-amazon.com/images/I/41RnRNOgDD...   \n",
            "107  https://m.media-amazon.com/images/I/511LXRAxI+...   \n",
            "\n",
            "                       primary_category  \n",
            "53                             Ottomans  \n",
            "262  Freestanding Wine Racks & Cabinets  \n",
            "139  Freestanding Wine Racks & Cabinets  \n",
            "298                   Adirondack Chairs  \n",
            "107               Sofa & Console Tables  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. NLP: Generate Text Embeddings ---\n",
        "\n",
        "# Reasoning: We are using a pre-trained model specialized in creating\n",
        "# meaningful sentence/paragraph embeddings. This model, 'all-MiniLM-L6-v2',\n",
        "# is fast, lightweight, and highly effective for semantic search.\n",
        "# This fulfills the NLP requirement.\n",
        "\n",
        "print(\"Initializing text embedding model (all-MiniLM-L6-v2)...\")\n",
        "# We use LangChain's HuggingFaceEmbeddings wrapper, as required [cite: 46]\n",
        "text_embedder = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    model_kwargs={'device': DEVICE}\n",
        ")\n",
        "\n",
        "print(\"Generating text embeddings for all products in the sample...\")\n",
        "# Get the list of texts to embed\n",
        "texts = df_sample['text_to_embed'].tolist()\n",
        "\n",
        "# Generate embeddings (this may take a minute)\n",
        "# .embed_documents() is the batch method\n",
        "text_embeddings = text_embedder.embed_documents(texts)\n",
        "\n",
        "# Add embeddings to our DataFrame\n",
        "df_sample['text_embedding'] = list(text_embeddings)\n",
        "\n",
        "print(\"Text embeddings generated successfully.\")\n",
        "print(f\"Vector dimension: {len(df_sample['text_embedding'].iloc[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59s8p-pxYhKV",
        "outputId": "7403ce4c-8a11-44a0-e857-e88045ce246d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing text embedding model (all-MiniLM-L6-v2)...\n",
            "Generating text embeddings for all products in the sample...\n",
            "Text embeddings generated successfully.\n",
            "Vector dimension: 384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. CV: Generate Image Embeddings ---\n",
        "\n",
        "# Reasoning: We need to represent our images as vectors. We chose CLIP,\n",
        "# a state-of-the-art model that embeds images and text in the same\n",
        "# space. This means a text query (\"wooden chair\") can find matching\n",
        "# image vectors, which is perfect for our recommendation goal.\n",
        "# This fulfills the CV requirement.\n",
        "\n",
        "# --- Load the token from the Colab Secrets ---\n",
        "HF_TOKEN = os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "\n",
        "if not HF_TOKEN:\n",
        "    print(\"=\"*50)\n",
        "    print(\"ERROR: HUGGINGFACEHUB_API_TOKEN not found.\")\n",
        "    print(\"Please add it to Colab Secrets and restart the runtime.\")\n",
        "    print(\"=\"*50)\n",
        "else:\n",
        "    print(\"Token found. Initializing CV embedding model (CLIP)...\")\n",
        "\n",
        "    # --- FIX: Explicitly pass the token to the loaders ---\n",
        "    model_name = \"openai/clip-vit-base-patch32\"\n",
        "\n",
        "    # Load the CLIP model and processor from HuggingFace, passing the token\n",
        "    clip_model = AutoModel.from_pretrained(\n",
        "        model_name,\n",
        "        token=HF_TOKEN\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    clip_processor = AutoProcessor.from_pretrained(\n",
        "        model_name,\n",
        "        token=HF_TOKEN\n",
        "    )\n",
        "\n",
        "    # --- Helper function to get image from URL ---\n",
        "    def get_image_embedding(image_url):\n",
        "        \"\"\"Downloads an image, processes it, and returns its CLIP embedding.\"\"\"\n",
        "        try:\n",
        "            # 1. Download image\n",
        "            response = requests.get(image_url, timeout=5)\n",
        "            response.raise_for_status() # Raise error for bad responses\n",
        "            image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "\n",
        "            # 2. Process image for CLIP\n",
        "            with torch.no_grad(): # Disable gradient calculation for inference\n",
        "                inputs = clip_processor(images=image, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
        "\n",
        "                # 3. Get the image features (embedding)\n",
        "                image_features = clip_model.get_image_features(**inputs)\n",
        "\n",
        "            return image_features.cpu().numpy().flatten().tolist()\n",
        "\n",
        "        except Exception as e:\n",
        "            # print(f\"Error processing image {image_url}: {e}\")\n",
        "            return None\n",
        "\n",
        "    # --- Generate Embeddings (with a progress bar) ---\n",
        "    print(f\"Generating image embeddings for {df_sample.shape[0]} items...\")\n",
        "\n",
        "    image_embeddings = []\n",
        "    for url in tqdm(df_sample['first_image_url']):\n",
        "        embedding = get_image_embedding(url)\n",
        "        image_embeddings.append(embedding)\n",
        "\n",
        "    df_sample['image_embedding'] = image_embeddings\n",
        "\n",
        "    # --- Clean up failed image downloads ---\n",
        "    failed_count = df_sample['image_embedding'].isna().sum()\n",
        "    if failed_count > 0:\n",
        "        print(f\"Warning: Failed to process {failed_count} images. They will be dropped.\")\n",
        "        df_sample = df_sample.dropna(subset=['image_embedding'])\n",
        "\n",
        "    print(f\"Image embeddings generated. New sample size: {df_sample.shape[0]}\")\n",
        "    print(f\"Vector dimension: {len(df_sample['image_embedding'].iloc[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "7446bb1a179f4f5d9df30dfb6fded8bc",
            "87868594ad6744e9b47a5ed3d61b90d2",
            "bf67f3ed11004016b964f905a8a1c2d5",
            "f340566de38240c6942444acff370618",
            "dc2e181e29ab4d9ab9fe6f3b584ec253",
            "7b460f0748d44fdca62ba2ae47f2fa82",
            "7989283e1a5d43b69c90c5a6d415e92e",
            "2178f3970af549d9a9a1e02ef03d08f5",
            "b8638cb9aa3f4bcbaaaa2be6b2e7154c",
            "7d6ac982565245eeaa96c9dae26ab167",
            "9e38b14962524ea791fd4924db1a9441"
          ]
        },
        "id": "gINsmX4XYsef",
        "outputId": "f96c758b-5dbe-4e05-a6db-72d068eb9e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token found. Initializing CV embedding model (CLIP)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating image embeddings for 210 items...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/210 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7446bb1a179f4f5d9df30dfb6fded8bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Failed to process 207 images. They will be dropped.\n",
            "Image embeddings generated. New sample size: 3\n",
            "Vector dimension: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Create Hybrid Embeddings ---\n",
        "\n",
        "# Reasoning: By concatenating text and image vectors, we create a\n",
        "# single \"hybrid\" vector that represents the product using *both* its\n",
        "# visual and textual features. A search query can then be vectorized\n",
        "# and compared against this rich vector for superior recommendations.\n",
        "\n",
        "# Text embedding dim: 384\n",
        "# Image embedding dim: 512\n",
        "# Hybrid embedding dim: 384 + 512 = 896\n",
        "\n",
        "def create_hybrid_embedding(row):\n",
        "    text_vec = np.array(row['text_embedding'])\n",
        "    image_vec = np.array(row['image_embedding'])\n",
        "\n",
        "    # Concatenate the two vectors\n",
        "    hybrid_vec = np.concatenate([text_vec, image_vec])\n",
        "\n",
        "    return hybrid_vec.tolist()\n",
        "\n",
        "print(\"Creating hybrid embeddings...\")\n",
        "df_sample['hybrid_embedding'] = df_sample.apply(create_hybrid_embedding, axis=1)\n",
        "\n",
        "HYBRID_VECTOR_DIMENSION = len(df_sample['hybrid_embedding'].iloc[0])\n",
        "print(f\"Hybrid embeddings created with dimension: {HYBRID_VECTOR_DIMENSION}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNFQaquqYxs0",
        "outputId": "982306a6-9ddf-4961-8b41-694d29bd2616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating hybrid embeddings...\n",
            "Hybrid embeddings created with dimension: 896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Store Embeddings in Vector DB (Pinecone) ---\n",
        "\n",
        "# Reasoning: A vector database is required[cite: 32]. We are using Pinecone\n",
        "# to store our 896-dimensional vectors. This allows for\n",
        "# \"semantic search\"—finding the most similar product vectors\n",
        "# to a user's query vector in milliseconds.\n",
        "\n",
        "if not PINECONE_API_KEY:\n",
        "    print(\"Skipping Pinecone: API key not found.\")\n",
        "else:\n",
        "    print(\"Initializing Pinecone...\")\n",
        "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "    INDEX_NAME = \"product-recommendation\"\n",
        "\n",
        "    # 1. Create the index (if it doesn't exist)\n",
        "    if INDEX_NAME not in pc.list_indexes().names():\n",
        "        print(f\"Creating new serverless index: {INDEX_NAME}\")\n",
        "        pc.create_index(\n",
        "            name=INDEX_NAME,\n",
        "            dimension=HYBRID_VECTOR_DIMENSION,\n",
        "            metric=\"cosine\", # Cosine similarity is good for semantic search\n",
        "            spec=ServerlessSpec(\n",
        "                cloud=\"aws\",\n",
        "                region=\"us-east-1\"\n",
        "            )\n",
        "        )\n",
        "        print(\"Index created.\")\n",
        "    else:\n",
        "        print(f\"Index '{INDEX_NAME}' already exists.\")\n",
        "\n",
        "    # 2. Connect to the index\n",
        "    index = pc.Index(INDEX_NAME)\n",
        "    print(index.describe_index_stats())\n",
        "\n",
        "    # 3. Format data for upsert\n",
        "    # We must include 'metadata' (the product details) so that\n",
        "    # when our API gets a match, it can return the title, price, etc.\n",
        "    vectors_to_upsert = []\n",
        "    for _, row in df_sample.iterrows():\n",
        "        # Ensure metadata values are in a valid format (e.g., non-null)\n",
        "        metadata = {\n",
        "            'title': str(row['title']),\n",
        "            'price': float(str(row['price']).replace('$', '').replace(',', '').strip()),\n",
        "            'brand': str(row.get('brand', 'Unknown')),\n",
        "            'category': str(row['primary_category']),\n",
        "            'image_url': str(row['first_image_url']),\n",
        "            'text': str(row['text_to_embed'])\n",
        "        }\n",
        "\n",
        "        vectors_to_upsert.append({\n",
        "            'id': str(row['uniq_id']),\n",
        "            'values': row['hybrid_embedding'],\n",
        "            'metadata': metadata\n",
        "        })\n",
        "\n",
        "    # 4. Upsert data in batches\n",
        "    # Reasoning: Upserting in batches is much more efficient than one by one.\n",
        "    BATCH_SIZE = 100\n",
        "    print(f\"Upserting {len(vectors_to_upsert)} vectors in batches of {BATCH_SIZE}...\")\n",
        "\n",
        "    for i in tqdm(range(0, len(vectors_to_upsert), BATCH_SIZE)):\n",
        "        batch = vectors_to_upsert[i : i + BATCH_SIZE]\n",
        "        index.upsert(vectors=batch)\n",
        "\n",
        "    print(\"--- Pinecone Upsert Complete ---\")\n",
        "    print(index.describe_index_stats())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "33070908f55b4ec6bc00640de3ca18a9",
            "8baae26f7edc425f8496fe7c131dac72",
            "c98021097f63482d90b2083c1565965b",
            "1c60a23344ee456dab1fd38f3f0192cc",
            "fba18c7f676f43a79bbccf1a45618183",
            "ec627cfccd26472fb405c2539d63c994",
            "f184fd9d12f1484aa7f2a9c6d033090a",
            "ad91ef734934498ba91b026d49204c5b",
            "39b4e78d1c5c48c7b9215946e309ddc0",
            "4b2754aaad97497ebd52fbaf8ab94ce0",
            "e9e638ca79c44ddfbff39c8b8f8b708d"
          ]
        },
        "id": "84P2hM8aZSLH",
        "outputId": "43ad9617-6d4e-4b39-9d79-5f1e5c9f190c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Pinecone...\n",
            "Index 'product-recommendation' already exists.\n",
            "{'dimension': 896,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'': {'vector_count': 3}},\n",
            " 'total_vector_count': 3,\n",
            " 'vector_type': 'dense'}\n",
            "Upserting 3 vectors in batches of 100...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33070908f55b4ec6bc00640de3ca18a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Pinecone Upsert Complete ---\n",
            "{'dimension': 896,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'': {'vector_count': 3}},\n",
            " 'total_vector_count': 3,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-google-genai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFvOfMH7wTg2",
        "outputId": "e748acd4-9dc3-42c6-ea85-26c744173794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (3.0.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.8.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.11.10)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.26.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.75.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.4.35)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.32.5)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyC11c84Sm2USn9BkIh9lh_nszObnHefKRM\""
      ],
      "metadata": {
        "id": "h5SGyF3BwaJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-core langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9oOTbOHxDEW",
        "outputId": "ffeeaa8b-921e-4aa8-ae87-7ffe52bc1267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (3.0.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.35)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.8.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.26.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.75.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (2.1.2)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (1.0.0)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain) (1.11.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. GenAI: Product Description Generator (New Approach: Google Gemini) ---\n",
        "\n",
        "# Import the required libraries\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# --- Load the token from the Colab Secrets ---\n",
        "if 'GOOGLE_API_KEY' not in os.environ:\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "    print(\"=\"*50)\n",
        "    print(\"ERROR: GOOGLE_API_KEY not found in environment.\")\n",
        "    print(\"Please add your key to Colab Secrets (key icon) and restart.\")\n",
        "    print(\"=\"*50)\n",
        "else:\n",
        "    print(\"Google API Key found! Initializing GenAI (Gemini) via LangChain...\")\n",
        "\n",
        "    try:\n",
        "        # --- THIS IS THE FIX ---\n",
        "        # We are using \"gemini-1.5-flash\" instead of \"gemini-pro\"\n",
        "        llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
        "\n",
        "        # 2. Create a Prompt Template\n",
        "        template = \"\"\"\n",
        "        You are a creative marketing assistant. Your task is to write a short,\n",
        "        engaging, and creative product description for a furniture website.\n",
        "        Do NOT just list the features. Make it sound appealing.\n",
        "\n",
        "        Product Details:\n",
        "        - Title: {title}\n",
        "        - Category: {category}\n",
        "        - Material: {material}\n",
        "\n",
        "        Your Creative Description:\n",
        "        \"\"\"\n",
        "        prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "        # 3. Create the LangChain chain\n",
        "        llm_chain = prompt | llm\n",
        "\n",
        "        # --- Test the GenAI Pipeline ---\n",
        "        print(\"\\n--- Testing GenAI Pipeline ---\")\n",
        "\n",
        "        test_product = df_sample.iloc[0]\n",
        "\n",
        "        # Handle 'nan' material value\n",
        "        material = test_product.get('material')\n",
        "        if pd.isna(material):\n",
        "            material_for_prompt = \"various high-quality materials\"\n",
        "        else:\n",
        "            material_for_prompt = str(material)\n",
        "\n",
        "        test_input = {\n",
        "            'title': test_product['title'],\n",
        "            'category': test_product['primary_category'],\n",
        "            'material': material_for_prompt\n",
        "        }\n",
        "\n",
        "        print(f\"Input for GenAI:\\n{test_input}\")\n",
        "\n",
        "        # 4. Run the chain\n",
        "        response = llm_chain.invoke(test_input)\n",
        "        generated_description = response.content\n",
        "\n",
        "        print(\"\\nGenerated Description:\")\n",
        "        print(generated_description)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n--- ERROR ---\")\n",
        "        print(\"The API call failed. This might be an issue with your API key or permissions.\")\n",
        "        print(f\"Details: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AmOn_pCZq-a",
        "outputId": "cec07492-70f7-48dd-f060-08681b16fa9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google API Key found! Initializing GenAI (Gemini) via LangChain...\n",
            "\n",
            "--- Testing GenAI Pipeline ---\n",
            "Input for GenAI:\n",
            "{'title': '#4203 Adjustable 1/4\" Threaded Non-Skid Leveling Glides Black Pad 4-Pack', 'category': 'Chairs', 'material': 'various high-quality materials'}\n",
            "\n",
            "Generated Description:\n",
            "Give your beloved chairs the unwavering support they deserve. These ingenious glides are the secret to perfectly stable seating and pristine floors. No more wobbles, no more scratches – just a smooth, silent glide and a rock-solid foundation for every moment. Elevate your comfort, protect your home.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. CV: Zero-Shot Classification and Evaluation ---\n",
        "\n",
        "# Reasoning: The PDF requires an \"image classification model\" and\n",
        "# [cite_start]\"model performance evaluation\"[cite: 30, 55]. Training a full CNN/ResNet\n",
        "# is too slow for this project. A \"zero-shot\" model is a clever\n",
        "# and modern solution. It uses a model like CLIP to see which text label\n",
        "# (e.g., \"Chair\", \"Sofa\") is most similar to the image, without any training.\n",
        "\n",
        "print(\"\\n--- Starting CV Model Evaluation (Zero-Shot) ---\")\n",
        "\n",
        "# --- Load the token from the Colab Secrets ---\n",
        "# We need this token to download the classifier model from Hugging Face.\n",
        "HF_TOKEN = os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "\n",
        "if not HF_TOKEN:\n",
        "    print(\"=\"*50)\n",
        "    print(\"ERROR: HUGGINGFACEHUB_API_TOKEN not found.\")\n",
        "    print(\"This cell needs the token to download the CLIP model.\")\n",
        "    print(\"Please add it to Colab Secrets and restart the runtime.\")\n",
        "    print(\"=\"*50)\n",
        "else:\n",
        "    print(\"Token found. Initializing zero-shot classification pipeline...\")\n",
        "\n",
        "    # 1. Load the zero-shot classification pipeline\n",
        "    # --- THIS IS THE FIX ---\n",
        "    # We must pass the token to the pipeline so it can\n",
        "    # download the model from Hugging Face without a 401 Error.\n",
        "    classifier = pipeline(\n",
        "        \"zero-shot-image-classification\",\n",
        "        model=\"openai/clip-vit-base-patch32\",\n",
        "        device=DEVICE,\n",
        "        token=HF_TOKEN  # <-- The added argument\n",
        "    )\n",
        "\n",
        "    # 2. Get our candidate labels (the real categories)\n",
        "    candidate_labels = df_sample['primary_category'].unique().tolist()\n",
        "    print(f\"Will classify images into {len(candidate_labels)} categories.\")\n",
        "\n",
        "    # 3. Run evaluation on a small sample (e.g., 50 items)\n",
        "    # (Running on all items would be slow)\n",
        "    eval_sample_size = 50\n",
        "    eval_df = df_sample.sample(n=min(eval_sample_size, df_sample.shape[0]))\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    print(f\"Running zero-shot classification on {eval_df.shape[0]} images...\")\n",
        "    for _, row in tqdm(eval_df.iterrows(), total=eval_df.shape[0]):\n",
        "        try:\n",
        "            # Get image from URL\n",
        "            response = requests.get(row['first_image_url'], timeout=5)\n",
        "            image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "\n",
        "            # Classify\n",
        "            preds = classifier(image, candidate_labels=candidate_labels)\n",
        "\n",
        "            # Store true label and predicted label\n",
        "            y_true.append(row['primary_category'])\n",
        "            y_pred.append(preds[0]['label']) # The label with the highest score\n",
        "\n",
        "        except Exception as e:\n",
        "            # print(f\"Error classifying image {row['first_image_url']}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # 4. Show Performance Evaluation\n",
        "    # [cite_start]Reasoning: This report fulfills the deliverable requirement[cite: 55].\n",
        "    # It shows how well our CV model can predict the correct category\n",
        "    # (Accuracy, Precision, Recall, F1-score).\n",
        "    print(\"\\n--- Model Performance Evaluation: CV (Zero-Shot) ---\")\n",
        "\n",
        "    # Ensure we have a consistent set of labels for the report\n",
        "    all_labels = sorted(list(set(y_true + y_pred)))\n",
        "\n",
        "    report = classification_report(y_true, y_pred, labels=all_labels, zero_division=0)\n",
        "    print(report)\n",
        "\n",
        "    print(\"\\n--- Model Training Notebook Complete ---\")\n",
        "    print(\"All models are built, and vectors are in Pinecone (if enabled).\")\n",
        "    print(\"Next step: Build the FastAPI backend.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "2c6d3120b0be41ada351d0093d8d6676",
            "2c8390aa92d8418f9baeaaa9b23fa05a",
            "3f8cc01b79b34596ab064245c24b670b",
            "76d83b593d244c69902747d234e5dd53",
            "7ac40f4670d644978e2f3045cdba6429",
            "9caf9b12d3ca474ab3fae74451ad10e5",
            "4dd6c77712564b7b9c73fcbfed4225fa",
            "036e7e8d99224a1f995de418bd5c7b22",
            "5ced8fb2763a4545ace2d6f2e95ca288",
            "c631dae62d934649bb90459a4e5a9028",
            "78ef43c91f074beaab47098f4a69e3a5"
          ]
        },
        "id": "ADki24zMsK3_",
        "outputId": "898dcd36-c03b-42a4-f989-d48f702c5af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting CV Model Evaluation (Zero-Shot) ---\n",
            "Token found. Initializing zero-shot classification pipeline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "Device set to use cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Will classify images into 3 categories.\n",
            "Running zero-shot classification on 3 images...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c6d3120b0be41ada351d0093d8d6676"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Performance Evaluation: CV (Zero-Shot) ---\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "                  Chairs       0.00      0.00      0.00         1\n",
            "Free Standing Shoe Racks       0.50      1.00      0.67         1\n",
            "    Wall-Mounted Mirrors       1.00      1.00      1.00         1\n",
            "\n",
            "                accuracy                           0.67         3\n",
            "               macro avg       0.50      0.67      0.56         3\n",
            "            weighted avg       0.50      0.67      0.56         3\n",
            "\n",
            "\n",
            "--- Model Training Notebook Complete ---\n",
            "All models are built, and vectors are in Pinecone (if enabled).\n",
            "Next step: Build the FastAPI backend.\n"
          ]
        }
      ]
    }
  ]
}